{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6528a52-8810-4bce-bf2f-7f8a0df74d10",
   "metadata": {},
   "source": [
    "#### This script does post-processing after obtaining merged patterns and a pattern matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8632aa1d-62db-400c-a1c5-cf90c64f5c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import crested\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d2f53-4c82-4ed2-be7a-385ee79c07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='/home/DeepHB/'\n",
    "os.chdir(dataDir)\n",
    "with open(os.path.join(dataDir,'TopicMPs.txt'), \"r\") as file:\n",
    "    labels = file.read().splitlines()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477bf63-2e60-4f79-80e6-18dd44a35f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## load the output of MergedMotifAcrossRuns\n",
    "with open('Outs/allpat_lstmv2_57MP_73.pkl', 'rb') as f:\n",
    "    all_patterns=pickle.load( f)\n",
    "\n",
    "with open('Outs/pm_lstmv2_57MP_73.pkl', 'rb') as f:\n",
    "    pattern_matrix=pickle.load( f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59fb6d-3c75-4e23-85fc-a99f92811f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dimensions seem to be same as for the job submission run using MergeModiscoRuns.py.\n",
    "## deleted that file\n",
    "print(len(all_patterns))\n",
    "print(pattern_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863d1f5-6831-4500-8071-eb15042ffa20",
   "metadata": {},
   "source": [
    "#### Obtianing seqlet count matrix\n",
    "#### I had used 'seqlet_count_log' for pattern matrix, below I can obtain seqlet-count per MP for each motif. I used the function 'create_pattern_matrix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c2cd4-dfaa-4389-9045-4fb10b18a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_parameter='seqlet_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26541460-f0c2-4230-80e9-54f7c5e43925",
   "metadata": {},
   "outputs": [],
   "source": [
    "##obtain pattern matrix from allpatterns\n",
    "classes=labels\n",
    "pat_mat = np.zeros((len(classes), len(all_patterns.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e2a4f-2cab-4277-a314-a8a586d0fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    " for p_idx in all_patterns:\n",
    "        p_classes = list(all_patterns[p_idx][\"classes\"].keys())\n",
    "        for ct in p_classes:\n",
    "            idx = np.argwhere(np.array(classes) == ct)[0][0]\n",
    "            avg_contrib = np.mean(all_patterns[p_idx][\"classes\"][ct][\"contrib_scores\"])\n",
    "            if pattern_parameter == \"contrib\":\n",
    "                pat_mat[idx, int(p_idx)] = avg_contrib\n",
    "            elif pattern_parameter == \"seqlet_count\":\n",
    "                sign = (\n",
    "                    1 if avg_contrib > 0 else -1\n",
    "                )  # Negative patterns will have a 'negative' count to reflect the negative performance.\n",
    "                pat_mat[idx, int(p_idx)] = (\n",
    "                    sign * all_patterns[p_idx][\"classes\"][ct][\"n_seqlets\"]\n",
    "                )\n",
    "            elif pattern_parameter == \"seqlet_count_log\":\n",
    "                sign = (\n",
    "                    1 if avg_contrib > 0 else -1\n",
    "                )  # Negative patterns will have a 'negative' count to reflect the negative performance.\n",
    "                pat_mat[idx, int(p_idx)] = sign * np.log1p(\n",
    "                    all_patterns[p_idx][\"classes\"][ct][\"n_seqlets\"]\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"Invalid pattern_parameter. Set to either 'contrib' or 'seqlet_count'.\"\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2205ca11-6d6c-478d-b632-aae9be030928",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_array = pat_mat[:, ~np.all(pat_mat == 0, axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42644e4a-3d9f-4139-bf33-27dc5bac1734",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_mat=filtered_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb75f1-6123-4893-8d8d-ad976eb97602",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac091e-d528-425f-ad8f-040a3d95f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Outs/pm_count_lstmv2_57MP_73.pkl', 'wb') as f:\n",
    "    pickle.dump(pat_mat, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fc0e76-841a-4d29-8f83-42b95a1903e1",
   "metadata": {},
   "source": [
    "## Infor regarding the merged patterns\n",
    "1. 'all_patterns' is a list of all the patterns that are obtained from merging. here there are 451 patterns. Each pattern has 6 elements first dict_keys(['pattern', 'pos_pattern', 'ppm', 'ic', 'instances', 'classes'])\n",
    "2. 'pattern' has dict_keys(['sequence', 'contrib_scores', 'hypothetical_contribs', 'seqlets', 'file_path', 'id', 'pos_pattern', 'n_seqlets', 'ic', 'ppm', 'class\n",
    "3. 'pos_pattern' mean if it is a postiive pattern or not\n",
    "4. 'ppm' probably Position Probability Matrix, with dimsnion nx4. 'ppm' is not present for all? for example absent for 0.\n",
    "5. 'ic' is a number\n",
    "6. 'instances' probably the number of sequences merged\n",
    "7. both ['pattern']['sequence'] and ['pattern']['ppm']  seems to be probability matrix. I am using ppm for homer motif dictionary creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2845d994-4c94-40e2-b115-bc44edb8617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331e834-2a08-44a8-8e0d-1da7fff217d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##this ia pattern seq info\n",
    "pat_seqs = crested.tl.modisco.generate_nucleotide_sequences(all_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f79e2e-6979-482a-9749-3d339760fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now extracting the name of each pattern the weight array for each one of them\n",
    "pat_names = []\n",
    "pat_weights = []\n",
    "\n",
    "for name, weight_array in pat_seqs:\n",
    "    pat_names.append(name)\n",
    "    pat_weights.append(weight_array)\n",
    "\n",
    "print(\"Names:\", pat_names)\n",
    "print(\"Weights:\", pat_weights)\n",
    "with open(\"all_pat_names.txt\", \"w\") as file:\n",
    "    for name in pat_names:\n",
    "        file.write(name + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae761f7f-373d-4e36-836c-a3b4a69fbb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Obtaining all the sequences and all the ppms from 165 patterns\n",
    "sequences = [v['pattern']['sequence'] for v in all_patterns.values()]\n",
    "ppms = [v['pattern']['ppm'] for v in all_patterns.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ad7e3-75ca-40f3-957e-50976c9e39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now obtaining consensus motif definiation from ppms\n",
    "\n",
    "# IUPAC code mapping for combinations of A, C, G, T\n",
    "IUPAC_CODES = {\n",
    "    frozenset(['A']): 'A', frozenset(['C']): 'C',\n",
    "    frozenset(['G']): 'G', frozenset(['T']): 'T',\n",
    "    frozenset(['A', 'G']): 'R', frozenset(['C', 'T']): 'Y',\n",
    "    frozenset(['G', 'C']): 'S', frozenset(['A', 'T']): 'W',\n",
    "    frozenset(['G', 'T']): 'K', frozenset(['A', 'C']): 'M',\n",
    "    frozenset(['A', 'C', 'G']): 'V', frozenset(['A', 'C', 'T']): 'H',\n",
    "    frozenset(['A', 'G', 'T']): 'D', frozenset(['C', 'G', 'T']): 'B',\n",
    "    frozenset(['A', 'C', 'G', 'T']): 'N'\n",
    "}\n",
    "\n",
    "BASES = ['A', 'C', 'G', 'T']\n",
    "\n",
    "def ppm_to_consensus(ppm, threshold=0.35):\n",
    "    consensus = ''\n",
    "    for row in ppm:\n",
    "        bases = [BASES[i] for i, val in enumerate(row) if val >= threshold]\n",
    "        if not bases:  # fallback if nothing exceeds threshold\n",
    "            max_base = BASES[np.argmax(row)]\n",
    "            bases = [max_base]\n",
    "        code = IUPAC_CODES[frozenset(bases)]\n",
    "        consensus += code\n",
    "    return consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d935a4-fd23-42cc-b148-d4b6fb0f88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensuses = [ppm_to_consensus(ppm) for ppm in ppms]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f250792-c13b-4bcc-901a-e30843de7fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensuses[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fcc999-bd1d-4f32-99fb-3ae9dea8b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pat_names[0:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c602fa-9e5a-440e-a7b9-a327fb609144",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqids = [f\"seqid_{i:03d}\" for i in range(1, 166)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b08bc-f5ee-4fc0-bec6-00dce2d2e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(seqids))\n",
    "print(len(all_patterns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd646a-2273-429d-8633-926cc1803c68",
   "metadata": {},
   "source": [
    "## Creating file for HOMER\n",
    "##### For homer I have have a third column info in header which is the log odd ratio score. Homer suggest to use below function to find the best match. alowwing for mismatches, reduces the score. since all motifs cannot be perfect, allowing mismatch is important. it also suggest that most motifs has score between 5-10. In converting JASPAR motifs to homer, the score is set to 6.23 for each motif. When I also converted my JASPAR herirarchial clusters into .motif, it calculcated some score that seems a bit above the below calcuclated score, but there is a trend, I need to see there how I calcuclated the score. Since I will not be running HOMER, i can use use a score which is 0.6 times the max log odd ration which allows some ground for mismatching?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79acee-f984-4fd5-849a-3a5219fd1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "##find thresold\n",
    "def max_log_odds_score(ppm, background=0.25):\n",
    "    max_probs = np.max(ppm, axis=1)\n",
    "    score = np.sum(np.log(max_probs / background))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce1168-26cd-43db-8fa1-5dbfab2efc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = [max_log_odds_score(ppm)for ppm in ppms]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75dd6d1-1efa-4480-9ba2-bb62b1819438",
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs = []\n",
    "for cons, thres_val, ppm, name in zip(consensuses, thres, ppms, seqids):\n",
    "    if len(cons) >= 4:\n",
    "        motifs.append({\n",
    "            'consensus': cons,\n",
    "            'thres': thres_val*0.75, ## i can use the scale here, no scaling for perfect match\n",
    "            'ppm': ppm,\n",
    "            'name': name\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1781e73d-c74a-4f69-9dde-99f43f7bea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dbbff7-b3a4-4e32-a719-fef92b949b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### seqid_048 didn't get covnerted, this is 'CCC', the only motif with size 3bp\n",
    "ppms[47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818316de-95b5-4b2e-9461-84a5681cd753",
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3b781-8738-4f98-99ff-fa8824827d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_homer_motifs_from_objects(motifs, output_file):\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for motif in motifs:\n",
    "            cons = motif['consensus']\n",
    "            name = motif['name']\n",
    "            ic = motif['thres']\n",
    "            ppm = motif['ppm']\n",
    "\n",
    "            f.write(f\">{cons}\\t{name}\\t{ic:.10f}\\n\")\n",
    "            for row in ppm:\n",
    "                f.write(\"\\t\".join(f\"{v:.6f}\" for v in row) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10859c54-6c4c-4e87-bcb9-e0e339af473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_homer_motifs_from_objects(motifs, \"allpat_lstmv2_57MP_73.motif\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crested2",
   "language": "python",
   "name": "crested2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
